
Number of parameters: 4203522
/data/digbose92/ads_complete_repo/ads_codes/model_files/recent_models/log_dir/LSTM_multi_layer_tone_transition_model/20230220-225938_LSTM_multi_layer_tone_transition_model/20230220-225938_LSTM_multi_layer_tone_transition_model.yaml
Early stop criteria:5
Number of epochs:50
INFO Starting training
INFO {'data': {'csv_file': '/data/digbose92/ads_complete_repo/ads_codes/SAIM-ADS/data/SAIM_ads_data_message_tone_train_test_val_clip_features.csv'}, 'parameters': {'batch_size': 16, 'train_shuffle': True, 'val_shuffle': False, 'epochs': 50, 'early_stop': 5, 'max_length': 333, 'fps': 4, 'base_fps': 24, 'num_workers': 4}, 'device': {'is_cuda': True}, 'loss': {'loss_option': 'bce_cross_entropy_loss'}, 'optimizer': {'choice': 'Adam', 'lr': '1e-3', 'gamma': 0.5, 'step_size': 15, 'scheduler': 'step_lr', 'mode': 'max', 'decay': 0.001, 'patience': 5, 'factor': 0.5, 'verbose': True}, 'model': {'option': 'LSTM_multi_layer_tone_transition_model', 'model_type': 'LSTM', 'embedding_dim': 512, 'n_hidden': 512, 'n_layers': 2, 'n_classes': 2, 'batch_first': True}, 'output': {'model_dir': '/data/digbose92/ads_complete_repo/ads_codes/model_files/recent_models/model_dir', 'log_dir': '/data/digbose92/ads_complete_repo/ads_codes/model_files/recent_models/log_dir'}}


 40%|██████████████████████████████████████████████████████████████████████▍                                                                                                         | 148/370 [00:07<00:10, 22.17it/s]INFO Training loss:0.716



 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 298/370 [00:14<00:03, 23.21it/s]INFO Training loss:0.693

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 370/370 [00:17<00:00, 21.28it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 370/370 [00:17<00:00, 20.86it/s]
INFO epoch: 1, time:17.77
INFO Epoch:1,Overall Training loss:0.690,Overall training Acc:0.534, Overall F1:0.446
INFO Evaluating the dataset
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 35.47it/s]
INFO Epoch:1,Overall Validation loss:0.690,Overall validation Acc:0.538, Overall F1:0.355
INFO Saving the best model
  0%|                                                                                                                                                                                          | 0/370 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "train_LSTM_model_tone_transition.py", line 277, in <module>
    main(config_data)
  File "train_LSTM_model_tone_transition.py", line 220, in main
    loss.backward()
  File "/data/digbose92/envs/miniconda3/envs/ads-env/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/digbose92/envs/miniconda3/envs/ads-env/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: cudnn RNN backward can only be called in training mode